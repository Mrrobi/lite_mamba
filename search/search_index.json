{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"lite-mamba","text":"<p>A minimal, pure-TensorFlow implementation of Mamba with a multi-dilated causal depthwise conv front-end. No custom C++ or Triton kernels needed; works seamlessly on CPU, GPU, or TPU with standard TensorFlow ops.</p>"},{"location":"#install","title":"Install","text":"<pre><code>pip install lite-mamba\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<pre><code>from lite_mamba import TFPTCNMamba\nimport tensorflow as tf\n\nx = tf.random.normal((2, 128, 512))  # (batch, seq, d_model)\nm = TFPTCNMamba(d_model=512, d_conv=3, conv_dilations=(1, 2, 4, 8))\ny = m(x)\nprint(y.shape)  # (2, 128, 512)\n</code></pre>"},{"location":"#conv-front-end-variants","title":"Conv front-end variants","text":"<ul> <li><code>TFPTCNMamba</code>: default Mamba variant, mixes parallel dilated depthwise conv branches via learned softmax gates.</li> <li><code>TFSTCNMamba</code>: runs the same depthwise conv layers in sequence (no gating); each branch output feeds the next to create a deterministic dilation stack.</li> <li><code>TFDPWCMamba</code>: pairs each depthwise branch with a pointwise (1x1) conv before the gating mix, adding extra channel mixing without stacking more layers.</li> <li><code>TFBaselineMamba</code>: single-branch baseline matching the reference Mamba architecture from state-spaces.</li> </ul> <p>All variants expose the same constructor signature (<code>d_model</code>, <code>d_state</code>, <code>conv_dilations</code>, etc.) and streaming helpers (<code>allocate_inference_cache</code>, <code>step</code>). Swap them simply by changing the imported class name:</p> <pre><code>from lite_mamba import TFSTCNMamba\n\nm = TFSTCNMamba(d_model=512, d_state=16, conv_dilations=(1, 2, 4))\n</code></pre>"},{"location":"#api-quick-reference","title":"API quick reference","text":"<p><code>TFMamba(d_model, d_state=16, d_conv=4, conv_dilations=(1,), expand=2, dt_rank=\"auto\", dt_min=0.001, dt_max=0.1, dt_init=\"random\", dt_scale=1.0, dt_init_floor=1e-4, conv_bias=True, bias=False, layer_idx=None)</code></p> <ul> <li><code>d_model</code> (int, required): input/output embedding size.</li> <li><code>d_state</code> (int, default 16): SSM state dimension per channel. Larger gives longer memory; increases compute.</li> <li><code>d_conv</code> (int, default 4): depthwise conv kernel size for each branch.</li> <li><code>conv_dilations</code> (tuple[int], default <code>(1,)</code>): dilation per branch. Multiple values create parallel dilated convs; effective receptive field is <code>(d_conv-1)*dilation</code>.</li> <li><code>expand</code> (float, default 2): inner width multiplier; sets <code>d_inner = expand * d_model</code>.</li> <li><code>dt_rank</code> (int or \"auto\", default \"auto\"): rank of delta projection. \"auto\" sets <code>ceil(d_model/16)</code>.</li> <li><code>dt_min</code>, <code>dt_max</code> (float, defaults 1e-3 / 1e-1): log-uniform range for delta initialization.</li> <li><code>dt_init</code> (\"random\" | \"constant\", default \"random\") and <code>dt_scale</code>, <code>dt_init_floor</code>: control delta init magnitude/stability.</li> <li><code>conv_bias</code> (bool, default True): include bias in depthwise convs.</li> <li><code>bias</code> (bool, default False): include bias in input/output linear projections.</li> <li><code>layer_idx</code> (int | None): identifier for streaming cache registration.</li> </ul>"},{"location":"#inference-streaming-helpers","title":"Inference / streaming helpers","text":"<ul> <li><code>allocate_inference_cache(batch_size, max_seqlen, dtype=None)</code>: preallocates conv and SSM state buffers for step-wise decoding.</li> <li><code>step(hidden_states, conv_state, ssm_state)</code>: single-token forward (expects <code>hidden_states</code> with shape <code>(B, 1, d_model)</code>).</li> </ul>"},{"location":"#highlights","title":"Highlights","text":"<ul> <li>Multi-branch Architecture: Parallel or stacked causal dilated convolutions with learned gating.</li> <li>Pure TensorFlow: No custom C++/CUDA kernels required. Compatible with XLA compilation (<code>tf.function(jit_compile=True)</code>).</li> <li>Streaming Support: Per-branch conv states and SSM state caching for autoregressive generation.</li> </ul>"},{"location":"#license","title":"License","text":"<p>Apache-2.0</p>"},{"location":"architecture/","title":"Architecture &amp; Variants","text":"<p>The <code>lite-mamba</code> library offers a pure-TensorFlow implementation of the Mamba architecture, featuring a unique multi-dilated causal depthwise convolution front-end. </p> <p>This diagram illustrates the core processing flow and how the different convolutional variants operate.</p>"},{"location":"architecture/#processing-flow","title":"Processing Flow","text":"<p>At a high level, the Mamba block performs the following sequence of operations:</p> <ol> <li>Input Projection: The input sequence is linearly projected to expand the feature dimension.</li> <li>Convolutional Front-end: The projected sequence passes through a causal 1D convolution layer. Here, <code>lite-mamba</code> introduces several multi-branch variants (detailed below) to replace the standard single depthwise convolution.</li> <li>SSM Parameter Projections: The convolutional output is projected to form the parameters ($\\Delta$, $B$, $C$) for the Selective State Space Model.</li> <li>Selective Scan: The core SSM recurrence is applied across the sequence.</li> <li>Output Projection: The SSM output is multiplicatively gated and projected back to the original model dimension.</li> </ol>"},{"location":"architecture/#convolutional-variants","title":"Convolutional Variants","text":"<p>The standard Mamba architecture uses a single depthwise causal convolution with a fixed kernel size. <code>lite-mamba</code> extends this with four distinct variants, accessible by importing the corresponding class:</p>"},{"location":"architecture/#1-tfptcnmamba-parallel-tcn","title":"1. TFPTCNMamba (Parallel TCN)","text":"<p>This is the default multi-branch implementation. Instead of a single convolution, it deploys multiple parallel depthwise convolutions, each with a different dilation rate (e.g., dilations 1, 2, 4, 8). </p> <ul> <li>Mechanism: The output of these parallel branches is mixed together using learned softmax gating coefficients. </li> <li>Benefit: This allows the model to dynamically attend to different receptive fields (short-term vs. long-term patterns) simultaneously.</li> </ul>"},{"location":"architecture/#2-tfstcnmamba-stacked-tcn","title":"2. TFSTCNMamba (Stacked TCN)","text":"<p>This variant arranges the different dilated depthwise convolutions sequentially rather than in parallel.</p> <ul> <li>Mechanism: The output of the dilation=1 branch feeds into the dilation=2 branch, which feeds into the dilation=4 branch, etc. There is no mixing gate.</li> <li>Benefit: Creates a deterministic, exponentially growing receptive field, similar to standard Temporal Convolutional Networks (TCNs). Useful for structural simplicity or debugging.</li> </ul>"},{"location":"architecture/#3-tfdpwcmamba-depthwise-pointwise","title":"3. TFDPWCMamba (Depthwise + Pointwise)","text":"<p>This variant enhances the parallel branches of <code>TFPTCNMamba</code> by pairing each depthwise branch with a pointwise ($1 \\times 1$) convolution before the gating mix.</p> <ul> <li>Mechanism: After the parallel dilated depthwise convolutions, a $1 \\times 1$ convolution mixes the channels within each branch.</li> <li>Benefit: Adds richer cross-channel interactions at the convolutional stage without needing to stack additional deep layers.</li> </ul>"},{"location":"architecture/#4-tfbaselinemamba-reference-baseline","title":"4. TFBaselineMamba (Reference Baseline)","text":"<p>This is a functional equivalent to the original <code>state-spaces/mamba</code> architecture.</p> <ul> <li>Mechanism: Employs a single causal depthwise convolution.</li> <li>Benefit: Provides a reliable baseline to measure the improvements of the multi-branch variants above.</li> </ul>"},{"location":"reference/api/","title":"API Reference","text":""},{"location":"reference/api/#lite_mamba.tf_mamba.TFMamba","title":"<code>lite_mamba.tf_mamba.TFMamba</code>","text":"<p>               Bases: <code>Layer</code></p> <p>TensorFlow Mamba block with parallel dilated depthwise causal conv branches.</p> Source code in <code>lite_mamba/tf_mamba.py</code> <pre><code>class TFMamba(tf.keras.layers.Layer):\n    \"\"\"TensorFlow Mamba block with parallel dilated depthwise causal conv branches.\"\"\"\n\n    def __init__(\n        self,\n        d_model,\n        d_state=16,\n        d_conv=4,\n        conv_dilations=(1,),\n        expand=2,\n        dt_rank=\"auto\",\n        dt_min=0.001,\n        dt_max=0.1,\n        dt_init=\"random\",\n        dt_scale=1.0,\n        dt_init_floor=1e-4,\n        conv_bias=True,\n        bias=False,\n        layer_idx=None,\n        stacked_convs=False,\n        pointwise=False,\n        **kwargs,\n    ):\n        super().__init__(**kwargs)\n        self.d_model = d_model\n        self.d_state = d_state\n        self.d_conv = d_conv\n        self.conv_dilations = tuple(conv_dilations)\n        self.num_conv_branches = len(self.conv_dilations)\n        self.conv_state_lens = [(self.d_conv - 1) * d + 1 for d in self.conv_dilations]\n        self.expand = expand\n        self.d_inner = int(self.expand * self.d_model)\n        self.dt_rank = math.ceil(self.d_model / 16) if dt_rank == \"auto\" else dt_rank\n        self.dt_min = dt_min\n        self.dt_max = dt_max\n        self.dt_init = dt_init\n        self.dt_scale = dt_scale\n        self.dt_init_floor = dt_init_floor\n        self.conv_bias = conv_bias\n        self.bias = bias\n        self.layer_idx = layer_idx\n        self.stacked_convs = stacked_convs\n        self.pointwise = pointwise\n\n        self.in_proj = tf.keras.layers.Dense(self.d_inner * 2, use_bias=self.bias)\n        self.x_proj = tf.keras.layers.Dense(self.dt_rank + self.d_state * 2, use_bias=False)\n        self.dt_proj = tf.keras.layers.Dense(self.d_inner, use_bias=True)\n        self.out_proj = tf.keras.layers.Dense(self.d_model, use_bias=self.bias)\n\n        if self.num_conv_branches &gt; 1 and not self.stacked_convs:\n            self.conv_gates = self.add_weight(\n                name=\"conv_gates\",\n                shape=(self.num_conv_branches,),\n                initializer=tf.keras.initializers.Ones(),\n                trainable=True,\n            )\n        else:\n            self.conv_gates = None\n\n        self.dw_kernels = []\n        self.dw_biases = []\n        self.pw_layers = []\n        for i in range(self.num_conv_branches):\n            self.dw_kernels.append(\n                self.add_weight(\n                    name=f\"dw_kernel_{i}\",\n                    shape=(self.d_conv, self.d_inner),\n                    initializer=tf.keras.initializers.GlorotUniform(),\n                    trainable=True,\n                )\n            )\n            if self.conv_bias:\n                self.dw_biases.append(\n                    self.add_weight(\n                        name=f\"dw_bias_{i}\",\n                        shape=(self.d_inner,),\n                        initializer=tf.keras.initializers.Zeros(),\n                        trainable=True,\n                    )\n                )\n            else:\n                self.dw_biases.append(None)\n            if self.pointwise:\n                self.pw_layers.append(tf.keras.layers.Dense(self.d_inner, use_bias=True))\n\n        a = tf.cast(tf.range(1, self.d_state + 1), tf.float32)\n        a = tf.tile(tf.expand_dims(a, 0), [self.d_inner, 1])\n        self.A_log = self.add_weight(\n            name=\"A_log\",\n            shape=(self.d_inner, self.d_state),\n            initializer=tf.constant_initializer(tf.math.log(a).numpy()),\n            trainable=True,\n        )\n        self.D = self.add_weight(\n            name=\"D\",\n            shape=(self.d_inner,),\n            initializer=tf.keras.initializers.Ones(),\n            trainable=True,\n        )\n\n    def build(self, input_shape):\n        self.in_proj.build((None, None, self.d_model))\n        self.x_proj.build((None, None, self.d_inner))\n        self.dt_proj.build((None, None, self.dt_rank))\n        self.out_proj.build((None, None, self.d_inner))\n        if self.pointwise:\n            for pw in self.pw_layers:\n                pw.build((None, None, self.d_inner))\n\n        dt_init_std = (self.dt_rank**-0.5) * self.dt_scale\n        if self.dt_init == \"constant\":\n            kernel = tf.fill([self.dt_rank, self.d_inner], tf.cast(dt_init_std, tf.float32))\n        elif self.dt_init == \"random\":\n            kernel = tf.random.uniform(\n                [self.dt_rank, self.d_inner],\n                minval=-dt_init_std,\n                maxval=dt_init_std,\n                dtype=tf.float32,\n            )\n        else:\n            raise NotImplementedError(f\"Unsupported dt_init: {self.dt_init}\")\n        self.dt_proj.kernel.assign(kernel)\n\n        log_min = math.log(self.dt_min)\n        log_max = math.log(self.dt_max)\n        dt = tf.exp(\n            tf.random.uniform([self.d_inner], minval=log_min, maxval=log_max, dtype=tf.float32)\n        )\n        dt = tf.maximum(dt, self.dt_init_floor)\n        inv_dt = dt + tf.math.log(-tf.math.expm1(-dt))\n        self.dt_proj.bias.assign(inv_dt)\n        super().build(input_shape)\n\n    @staticmethod\n    def _causal_depthwise_conv1d(x, kernel, bias=None, dilation=1):\n        # x: (B, L, D), kernel: (K, D)\n        k = kernel.shape[0]\n        pad_left = dilation * (k - 1)\n        xpad = tf.pad(x, [[0, 0], [pad_left, 0], [0, 0]])\n        seqlen = tf.shape(x)[1]\n        taps = [xpad[:, i * dilation : i * dilation + seqlen, :] for i in range(k)]\n        stacked = tf.stack(taps, axis=2)  # (B, L, K, D)\n        y = tf.reduce_sum(stacked * tf.reshape(kernel, [1, 1, k, -1]), axis=2)\n        if bias is not None:\n            y = y + tf.reshape(bias, [1, 1, -1])\n        return tf.nn.silu(y)\n\n    def _run_branch(self, x, branch_idx):\n        y = self._causal_depthwise_conv1d(\n            x,\n            kernel=self.dw_kernels[branch_idx],\n            bias=self.dw_biases[branch_idx],\n            dilation=self.conv_dilations[branch_idx],\n        )\n        if self.pointwise:\n            y = self.pw_layers[branch_idx](y)\n        return y\n\n    def call(self, hidden_states, training=None):\n        # hidden_states: (B, L, D)\n        xz = self.in_proj(hidden_states)\n        x, z = tf.split(xz, num_or_size_splits=2, axis=-1)\n        A = -tf.exp(tf.cast(self.A_log, tf.float32))\n\n        if self.stacked_convs:\n            for i in range(self.num_conv_branches):\n                x = self._run_branch(x, i)\n        else:\n            conv_outputs = [self._run_branch(x, i) for i in range(self.num_conv_branches)]\n            if self.conv_gates is None:\n                x = conv_outputs[0]\n            else:\n                gate = tf.nn.softmax(self.conv_gates, axis=0)\n                x = tf.add_n([gate[i] * conv_outputs[i] for i in range(self.num_conv_branches)])\n\n        x_dbl = self.x_proj(x)\n        dt, B, C = tf.split(\n            x_dbl,\n            num_or_size_splits=[self.dt_rank, self.d_state, self.d_state],\n            axis=-1,\n        )\n\n        # Match PyTorch path: apply dt_proj weights here, then add bias/softplus inside scan.\n        dt = tf.einsum(\"blr,rd-&gt;bld\", dt, self.dt_proj.kernel)\n\n        y = selective_scan_tf(\n            x,\n            dt,\n            A,\n            B,\n            C,\n            self.D,\n            z=z,\n            delta_bias=self.dt_proj.bias,\n            delta_softplus=True,\n            return_last_state=False,\n        )\n        return self.out_proj(y)\n\n    def allocate_inference_cache(self, batch_size, max_seqlen, dtype=tf.float32):\n        conv_state = [\n            tf.zeros([batch_size, state_len, self.d_inner], dtype=dtype)\n            for state_len in self.conv_state_lens\n        ]\n        ssm_state = tf.zeros([batch_size, self.d_inner, self.d_state], dtype=dtype)\n        return conv_state, ssm_state\n\n    def step(self, hidden_states, conv_state, ssm_state):\n        # hidden_states: (B, 1, D)\n        xz = self.in_proj(hidden_states[:, 0, :])\n        x, z = tf.split(xz, num_or_size_splits=2, axis=-1)\n        A = -tf.exp(tf.cast(self.A_log, tf.float32))\n        dtype = hidden_states.dtype\n\n        def branch_step(x_in, state, kernel, bias, dilation, pw_layer):\n            x_state = tf.concat([state[:, 1:, :], tf.expand_dims(x_in, axis=1)], axis=1)\n            k = kernel.shape[0]\n            idx = tf.range(k - 1, -1, -1) * dilation\n            pos = tf.shape(x_state)[1] - 1 - idx\n            values = tf.gather(x_state, pos, axis=1)  # (B, K, D), oldest-&gt;newest\n            y = tf.reduce_sum(values * tf.reshape(kernel, [1, k, self.d_inner]), axis=1)\n            if bias is not None:\n                y = y + bias\n            y = tf.nn.silu(y)\n            if pw_layer is not None:\n                y = pw_layer(y)\n            return y, x_state\n\n        if self.stacked_convs:\n            new_states = []\n            for i in range(self.num_conv_branches):\n                pw = self.pw_layers[i] if self.pointwise else None\n                x, new_state = branch_step(\n                    x,\n                    conv_state[i],\n                    self.dw_kernels[i],\n                    self.dw_biases[i],\n                    self.conv_dilations[i],\n                    pw,\n                )\n                new_states.append(new_state)\n        else:\n            branch_outputs = []\n            new_states = []\n            for i in range(self.num_conv_branches):\n                pw = self.pw_layers[i] if self.pointwise else None\n                xi, new_state = branch_step(\n                    x,\n                    conv_state[i],\n                    self.dw_kernels[i],\n                    self.dw_biases[i],\n                    self.conv_dilations[i],\n                    pw,\n                )\n                branch_outputs.append(xi)\n                new_states.append(new_state)\n            if self.conv_gates is None:\n                x = branch_outputs[0]\n            else:\n                gate = tf.nn.softmax(self.conv_gates, axis=0)\n                x = tf.add_n([gate[i] * branch_outputs[i] for i in range(self.num_conv_branches)])\n\n        x_db = self.x_proj(x)\n        dt, B, C = tf.split(\n            x_db,\n            num_or_size_splits=[self.dt_rank, self.d_state, self.d_state],\n            axis=-1,\n        )\n        dt = tf.einsum(\"br,rd-&gt;bd\", dt, self.dt_proj.kernel)\n        dt = tf.nn.softplus(dt + self.dt_proj.bias)\n        dA = tf.exp(tf.einsum(\"bd,dn-&gt;bdn\", dt, A))\n        dB = tf.einsum(\"bd,bn-&gt;bdn\", dt, B)\n        new_ssm_state = ssm_state * dA + tf.expand_dims(x, axis=-1) * dB\n        y = tf.einsum(\"bdn,bn-&gt;bd\", tf.cast(new_ssm_state, dtype), C)\n        y = y + tf.cast(self.D, dtype) * x\n        y = y * tf.nn.silu(z)\n        out = self.out_proj(y)\n        return tf.expand_dims(out, axis=1), new_states, new_ssm_state\n</code></pre>"},{"location":"reference/api/#lite_mamba.tf_mamba.TFBaselineMamba","title":"<code>lite_mamba.tf_mamba.TFBaselineMamba</code>","text":"<p>               Bases: <code>TFMamba</code></p> <p>Single-branch TensorFlow baseline Mamba.</p> Source code in <code>lite_mamba/tf_mamba.py</code> <pre><code>class TFBaselineMamba(TFMamba):\n    \"\"\"Single-branch TensorFlow baseline Mamba.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        kwargs.pop(\"conv_dilations\", None)\n        super().__init__(*args, conv_dilations=(1,), **kwargs)\n</code></pre>"},{"location":"reference/api/#lite_mamba.tf_mamba.TFPTCNMamba","title":"<code>lite_mamba.tf_mamba.TFPTCNMamba</code>","text":"<p>               Bases: <code>TFMamba</code></p> <p>Parallel TCN branches (TensorFlow variant).</p> Source code in <code>lite_mamba/tf_mamba.py</code> <pre><code>class TFPTCNMamba(TFMamba):\n    \"\"\"Parallel TCN branches (TensorFlow variant).\"\"\"\n</code></pre>"},{"location":"reference/api/#lite_mamba.tf_mamba.TFSTCNMamba","title":"<code>lite_mamba.tf_mamba.TFSTCNMamba</code>","text":"<p>               Bases: <code>TFMamba</code></p> <p>Stacked TCN branches (TensorFlow variant).</p> Source code in <code>lite_mamba/tf_mamba.py</code> <pre><code>class TFSTCNMamba(TFMamba):\n    \"\"\"Stacked TCN branches (TensorFlow variant).\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, stacked_convs=True, **kwargs)\n</code></pre>"},{"location":"reference/api/#lite_mamba.tf_mamba.TFDPWCMamba","title":"<code>lite_mamba.tf_mamba.TFDPWCMamba</code>","text":"<p>               Bases: <code>TFMamba</code></p> <p>Depthwise + pointwise branch variant (TensorFlow).</p> Source code in <code>lite_mamba/tf_mamba.py</code> <pre><code>class TFDPWCMamba(TFMamba):\n    \"\"\"Depthwise + pointwise branch variant (TensorFlow).\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, pointwise=True, **kwargs)\n</code></pre>"}]}